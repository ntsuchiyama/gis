---
title: "Week 6 practical"
output: html_document
date: '2022-11-16'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Research Question: “For any given London Borough, are the Blue Plaques within that borough distributed randomly or do they exhibit some kind of dispersed or clustered pattern?”

```{r message=FALSE, warning=FALSE}

#library the packages needed
library(spatstat)
library(here)
library(sp)
library(rgeos)
library(maptools)
library(tmap)
library(sf)
library(geojson)
library(geojsonio)
library(tmaptools)
library(tidyverse)

```


## Setting up the data 

```{r message=FALSE, warning=FALSE}

# get the boundaries of London boroughs
london_boroughs <- st_read("statistical-gis-boundaries-london/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp") %>% st_transform(.,27700)

# check the data
st_crs(london_boroughs)

# map the boroughs
qtm(london_boroughs)

```

```{r message=FALSE, warning=FALSE}
summary(london_boroughs)
```

```{r message=FALSE, warning=FALSE}

# read in the data for the locations of the blue plaques
blue_plaques <- st_read("open-plaques-london-2018-04-08.geojson") %>% st_transform(.,27700)

```

```{r message=FALSE, warning=FALSE}
summary(blue_plaques)
```

```{r message=FALSE, warning=FALSE}

#plot the blue plaques in the city
tmap_mode("plot")
tm_shape(london_boroughs) +
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(blue_plaques) +
  tm_dots(col = "blue")

```

# Data cleaning 

Need to remove any plaques with the same grid reference 

```{r message=FALSE, warning=FALSE}
blue_plaques <- distinct(blue_plaques)
```

# Spatial subsetting

Only select the points within the London boroughs

```{r message=FALSE, warning=FALSE}

blue_plaques_london <- blue_plaques[london_boroughs,] 

# check to see the locations 
tmap_mode("plot")
tm_shape(london_boroughs) +
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(blue_plaques_london) +
  tm_dots(col = "blue")

```

- use st_intersect() to have the indices of where they intersect
- st_equals returns true when the two sf objects have the same geometry 

```{r message=FALSE, warning=FALSE}

intersect_indices <-st_intersects(london_boroughs, blue_plaques, sparse = FALSE)

```

# spatial clipping

taking layers and extracting 

# spatial joining 

```{r}

# read in hotel location data from osm, transform projection to BNG
osm_hotel <- st_read("greater-london-latest-free.shp/gis_osm_pois_a_free_1.shp") %>%
  st_transform(., 27700) %>%
  filter(fclass == "hotel")
```

```{r message=FALSE, warning=FALSE}

# join the hotel dataset with londonboroughs - gives the borough each of the hotels are located in 
join_example <-  st_join(osm_hotel, london_boroughs)
nrow(join_example)

```

```{r message=FALSE, warning=FALSE}

# read in the .csv and make it into spatial data

Airbnb <- read_csv("listings.csv") %>%
  st_as_sf(., coords = c("longitude", "latitude"), 
                   crs = 4326) %>%
    st_transform(., 27700)%>%
    #select entire places that are available all year
    filter(room_type == 'Entire home/apt' & availability_365 =='365')

```

```{r message=FALSE, warning=FALSE}

# make function for joining the data, make a new column for the number of 'hotels' in borough
Joinfun <- function(data1, data2){

output<- data1%>%
  st_join(london_boroughs,.) %>%
  add_count(GSS_CODE, name="hotels_in_borough") 

  return(output)
}

```

```{r message=FALSE, warning=FALSE}

# use the function for hotels
Hotels <- Joinfun(osm_hotel, london_boroughs)

# then for airbnb
Airbnb <- Joinfun(Airbnb, london_boroughs)

```

```{r message=FALSE, warning=FALSE}

# at the moment each hotel/airbnb is a row for the borough
# create rows that has the number of hotels/airbnb

Hotels_sum <- Hotels %>%
  group_by(., GSS_CODE, NAME)%>%
  summarise(`Accomodation count` = unique(hotels_in_borough))

Airbnb_sum <- Airbnb %>%
  group_by(., GSS_CODE, NAME)%>%
  summarise(`Accomodation count` = unique(hotels_in_borough))
```

Join the hotel data and the airbnb data! - need to use st_join as both are spatial data
- st_join uses st_intersects by default - 

```{r message=FALSE, warning=FALSE}

all_accomodation <- st_join(Hotels_sum, Airbnb_sum)

head(all_accomodation)

```

```{r}
all_accomodation <- st_join(Hotels_sum, Airbnb_sum, join = st_equals)

head(all_accomodation)
```

# Key points

- Select points or polygons in a polygon = Selecting data by location = spatial sub-setting

- Determine where datasets overlap (or touch, or don’t overlap) and extract those parts = spatial clipping

- Join two spatial datasets together = spatial joining, which can use spatial subsetting functions as the default is st_intersects(); This function joins spatial data

- Selecting data by attributes = filtering or selecting rows / columns with dplyr

# Study Area

choosing the borough of Harrow to focus on as running the analysis for the whole of London is going to take time; will enable us to compare

```{r message=FALSE, warning=FALSE}

# extract the borough by selecting by attribute
Harrow <- london_boroughs %>%
  filter(., NAME=="Harrow")

#Check to see that the correct borough has been pulled out
tm_shape(Harrow) +
  tm_polygons(col = NA, alpha = 0.5)

```

```{r message=FALSE, warning=FALSE}

# clip the blue plaques data to our single borough
blue_plaques_harrow <- blue_plaques[Harrow,]

#check that it's worked
tmap_mode("plot")
tm_shape(Harrow) +
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(blue_plaques_harrow) +
  tm_dots(col = "blue")

```

start the analysis with spatstat
 
- create an observation window for spatstatto carryout the analysis within

```{r message=FALSE, warning=FALSE}
# set a window as the borough boundary
window <- as.owin(Harrow)
plot(window)
```

- create a point pattern (ppp) object to use with spatstat

```{r message=FALSE, warning=FALSE}

# create a sp object
blue_plaques_harrow_sp <- blue_plaques_harrow %>%
  as(., 'Spatial')

# create a ppp object
blue_plaques_harrow_ppp <- ppp(x=blue_plaques_harrow_sp@coords[,1], y=blue_plaques_harrow_sp@coords[,2], window=window)

```

have a look at the new object

```{r message=FALSE, warning=FALSE}
blue_plaques_harrow_ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Blue Plaques Harrow")
```

## Point pattern analysis

# Kernel Density Estimation

plot the density of points using a kernel

```{r}
blue_plaques_harrow_ppp %>%
  density(., sigma=500) %>%
  plot()
```

sigma value sets the diameter of the Kernel (in the units your map is in — in this case, as we are in British National Grid the units are in metres)

```{r}
blue_plaques_harrow_ppp %>%
  density(., sigma=1000) %>%
  plot()
```

# Quadrat Analysis

does the distribution of points differ from 'complete spatial randomness'?

Quadrat test - most basic, not recommended

```{r}
# First plot the points
plot(blue_plaques_harrow_ppp,
     pch=16,
     cex=0.5, 
     main="Blue Plaques in Harrow")

# now count the points in that fall in a 6 x 6 grid overlaid across the window 
blue_plaques_harrow_ppp %>%
  quadratcount(.,nx = 6, ny = 6)%>%
    plot(., add=T, col="red")
```

whether or not there is any kind of spatial patterning associated with the Blue Plaques in areas of London - comparing with csr which is based on the poisson distribution

saving the results in to a table

```{r}
# run the quadrat count
Qcount <- blue_plaques_harrow_ppp %>%
  quadratcount(.,nx = 6, ny = 6) %>%
  as.data.frame() %>%
  dplyr::count(Var1=Freq)%>%
  dplyr::rename(Freqquadratcount=n)

# check data type (convert to numeric if factor)
Qcount %>% 
  summarise_all(class)

```

Pr = (X=k) = (λ^k*e^−λ)/k!
- x is the number of occurrences
- λ is the mean number of occurrences
- e is a constant - 2.718

```{r}
sums <- Qcount %>%
  #calculate the total blue plaques (Var * Freq)
  mutate(total = Var1 * Freqquadratcount) %>%
  dplyr::summarise(across(everything(), sum))%>%
  dplyr::select(-Var1) 

lambda<- Qcount%>%
  #calculate lambda
  mutate(total = Var1 * Freqquadratcount)%>%
  dplyr::summarise(across(everything(), sum)) %>%
  mutate(lambda=total/Freqquadratcount) %>%
  dplyr::select(lambda)%>%
  pull(lambda)
```

Calculate expected using the Poisson formula from above
k is the number of blue plaques counted in a square and is found in the first column of our table

```{r}
QCountTable <- Qcount %>%
  mutate(Pr=((lambda^Var1)*exp(-lambda))/factorial(Var1))%>%
  #now calculate the expected counts based on our total number of plaques
  #and save them to the table
  mutate(Expected= (round(Pr * sums$Freqquadratcount, 0)))

#Compare the frequency distributions of the observed and expected point patterns
plot(c(1,5),c(0,14), type="n",
xlab="Number of Blue Plaques (Red=Observed,Blue=Expected)", 
     ylab="Frequency of Occurances")
points(QCountTable$Freqquadratcount, 
       col="Red", 
       type="o", 
       lwd=3)
points(QCountTable$Expected, col="Blue", 
       type="o", 
       lwd=3)
```

quadrat.test - uses a Chi Squared test to compare the observed and expected frequencies for each quadrant

p-value > 0.05 - we have CSR and there is no pattern in our points
p-value < 0.05 - we do have clustering in our points

```{r}
teststats <- quadrat.test(blue_plaques_harrow_ppp, nx = 6, ny = 6)

plot(blue_plaques_harrow_ppp,pch=16,cex=0.5, main="Blue Plaques in Harrow")
plot(teststats, add=T, col = "red")
```

top-left figure: the observed count of points
top-right: Poisson expected number of points
the bottom value: the residual value (also known as Pearson residual value), or (Observed - Expected) / Sqrt(Expected)

consideration 
- the Poisson distribution only describes observed occurrences that are counted in integers; where our occurrences = 0 (i.e. not observed), this can be an issue
- MAUP

```{r}

```

# Ripley’s K

addressing the limitations of quadrat analysis - compare the observed distribution of points with the Poisson random model for a whole range of different distance radii

```{r}
K <- blue_plaques_harrow_ppp %>%
  Kest(., correction="border") %>%
  plot()
```

Red line: the theoretical value of K for each distance window (r) under a Poisson assumption of Complete Spatial Randomness
Black line: the estimated values of K accounting for the effects of the edge of the study area. 

- Where the value of K falls above the line, the data appear to be clustered at that distance
- Where the value of K is below the line, the data are dispersed

## Density-based spatial clustering of applications with noise: DBSCAN

WHERE in our area of interest the clusters are occurring

```{r}
## libraries needed to install
library(raster)
library(fpc)
```

```{r message=FALSE, warning=FALSE}
#first check the coordinate reference system of the Harrow spatial polygon:
st_geometry(london_boroughs)
```

two parameters required to input
- Epsilon: the radius within which the algorithm with search for clusters 
- MinPts: this is the minimum number of points that should be considered a cluster

```{r}
# extract the points from the spatial points data frame
blue_plaques_harrow_points <- blue_plaques_harrow_sp %>%
  coordinates(.)%>%
  as.data.frame()

# now run the dbscan analysis
# eps is set based on ripley's k - clustering measures
db <- blue_plaques_harrow_points %>%
  fpc::dbscan(.,eps = 700, MinPts = 4)

# plot the results
plot(db, blue_plaques_harrow_points, main = "DBSCAN Output", frame = F)
plot(london_boroughs$geometry, add=T)
```

```{r message=FALSE, warning=FALSE}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
library(dbscan)

blue_plaques_harrow_points %>%
  dbscan::kNNdistplot(.,k=4)
```

The plot shows for each point the average distance to the k neighbours, which are then plotted in ascending order. The knee is where this value (of distance to neighbours) increases.

making more aesthetically pleasing plots!!
- extract information from db and use ggplot2

```{r message=FALSE, warning=FALSE}
library(ggplot2)
```

db object - includes info about the cluster each point belongs to, whether the point is a seed point or edge point

```{r message=FALSE, warning=FALSE}
# retrieve a summary of the object
db
```

```{r message=FALSE, warning=FALSE}
# cluster membership
db$cluster
```

```{r message=FALSE, warning=FALSE}
# add the cluster membership to the dataframe
blue_plaques_harrow_points<- blue_plaques_harrow_points %>%
  mutate(dbcluster=db$cluster)
```

```{r message=FALSE, warning=FALSE}
# create convex hull polygons to wrap around the points in the clusters
chulls <- blue_plaques_harrow_points %>%
  group_by(dbcluster) %>%
  # first hull - give the count of numbers
  dplyr::mutate(hull = 1:n(),
  # chull - Compute Convex Hull of a Set of Points
  hull = factor(hull, chull(coords.x1, coords.x2))) %>%
  # have the ones that create convex hull on type
  arrange(hull)
```

```{r message=FALSE, warning=FALSE}
# drop group 0 as it is not a cluster 
chulls <- chulls %>%
  filter(dbcluster >=1)
```

```{r message=FALSE, warning=FALSE}
dbplot <- ggplot(data=blue_plaques_harrow_points, 
                 aes(coords.x1,coords.x2, colour=dbcluster, fill=dbcluster)) 
# add the points in
dbplot <- dbplot + geom_point()
# now the convex hulls
dbplot <- dbplot + geom_polygon(data = chulls, aes(coords.x1,coords.x2, group=dbcluster), alpha = 0.5) 
# now plot, setting the coordinates to scale correctly and as a black and white plot 
# (just for the hell of it)...
dbplot + theme_bw() + coord_equal()
```

```{r message=FALSE, warning=FALSE}
# add a basemap
# First get the bbox in lat long for Harrow
HarrowWGSbb <- Harrow %>%
  st_transform(., 4326)%>%
  st_bbox()
```

```{r message=FALSE, warning=FALSE}
library(OpenStreetMap)

basemap <- OpenStreetMap::openmap(c(51.5549876,-0.4040502),c(51.6405356,-0.2671315), zoom=NULL, "stamen-toner")

# convert the basemap to British National Grid
basemap_bng <- openproj(basemap, projection="+init=epsg:27700")
```

```{r message=FALSE, warning=FALSE}
#autoplot(basemap_bng) sometimes works
autoplot.OpenStreetMap(basemap_bng)+ 
  geom_point(data=blue_plaques_harrow_points, 
             aes(coords.x1,coords.x2, 
                 colour=dbcluster, 
                 fill=dbcluster)) + 
  geom_polygon(data = chulls, 
               aes(coords.x1,coords.x2, 
                   group=dbcluster,
                   fill=dbcluster), 
               alpha = 0.5)  
```



